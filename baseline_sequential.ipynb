{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feeae7ab",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07145fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    'pyspark',\n",
    "    'pandas',\n",
    "    'numpy',\n",
    "    'matplotlib',\n",
    "    'seaborn',\n",
    "    'scikit-learn'\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(f\" {package} installed\")\n",
    "\n",
    "print(\"\\n All packages installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f918b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PySpark (for Google Colab)\n",
    "!pip install pyspark -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e387e717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\" Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09045a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session with 1 executor (Sequential Baseline)\n",
    "import sys\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RandomForest_Sequential_Baseline\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\") \\\n",
    "    .config(\"spark.default.parallelism\", \"1\") \\\n",
    "    .config(\"spark.pyspark.python\", sys.executable) \\\n",
    "    .config(\"spark.pyspark.driver.python\", sys.executable) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\" Spark Session initialized\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Master: {spark.sparkContext.master}\")\n",
    "print(f\"Executors: 1 (Sequential Mode)\")\n",
    "print(f\"Python executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a95b90",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e84f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Covertype dataset using scikit-learn (cache locally for reuse)\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "print(\"Preparing Covertype dataset...\")\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "local_csv = data_dir / \"covtype.csv\"\n",
    "\n",
    "if local_csv.exists():\n",
    "    print(f\"Loading dataset from local cache: {local_csv}\")\n",
    "    df_pandas = pd.read_csv(local_csv)\n",
    "else:\n",
    "    print(\"Downloading Covertype dataset...\")\n",
    "    covtype = fetch_covtype(as_frame=True)\n",
    "    df_pandas = covtype.frame\n",
    "    df_pandas.to_csv(local_csv, index=False)\n",
    "    print(f\" Dataset cached locally: {local_csv}\")\n",
    "\n",
    "print(\" Dataset ready\")\n",
    "print(f\"Shape: {df_pandas.shape}\")\n",
    "print(f\"Columns: {df_pandas.columns.tolist()[:5]}...\")  # Show first 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b87f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Spark DataFrame\n",
    "print(\"Converting to Spark DataFrame...\")\n",
    "spark_df = spark.createDataFrame(df_pandas)\n",
    "\n",
    "# Verify data\n",
    "print(f\" Spark DataFrame created\")\n",
    "print(f\"Rows: {spark_df.count():,}\")\n",
    "print(f\"Columns: {len(spark_df.columns)}\")\n",
    "\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db289472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing: Feature assembly\n",
    "print(\"Preparing features...\")\n",
    "\n",
    "# Get feature column names (all except target)\n",
    "feature_cols = [col for col in spark_df.columns if col != 'Cover_Type']\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "\n",
    "# Assemble features into a single vector\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "data = assembler.transform(spark_df)\n",
    "\n",
    "# Rename target column to 'label' (required by MLlib)\n",
    "data = data.withColumnRenamed('Cover_Type', 'label')\n",
    "\n",
    "# Select only necessary columns\n",
    "data = data.select('features', 'label')\n",
    "\n",
    "print(\" Features assembled\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed726c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80-20)\n",
    "print(\"Splitting data into train and test sets...\")\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Partition and cache for performance\n",
    "train_data = train_data.repartition(4).cache()\n",
    "test_data = test_data.cache()\n",
    "\n",
    "# Materialize the cache\n",
    "train_count = train_data.count()\n",
    "test_count = test_data.count()\n",
    "\n",
    "print(f\" Data split complete\")\n",
    "print(f\"Training samples: {train_count:,}\")\n",
    "print(f\"Test samples: {test_count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44694b0",
   "metadata": {},
   "source": [
    "## 3. Sequential Random Forest Training\n",
    "\n",
    "Train Random Forest with different tree counts to establish baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace7bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_rf(train_data, test_data, num_trees, max_depth=10, exp_id=\"\"):\n",
    "    \"\"\"\n",
    "    Train Random Forest and measure performance\n",
    "    \n",
    "    Args:\n",
    "        train_data: Spark DataFrame for training\n",
    "        test_data: Spark DataFrame for testing\n",
    "        num_trees: Number of trees in the forest\n",
    "        max_depth: Maximum depth of each tree\n",
    "        exp_id: Experiment identifier\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing metrics and model\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Experiment {exp_id}: Training with {num_trees} trees\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Configure Random Forest\n",
    "    rf = RandomForestClassifier(\n",
    "        numTrees=num_trees,\n",
    "        maxDepth=max_depth,\n",
    "        seed=42,\n",
    "        labelCol='label',\n",
    "        featuresCol='features'\n",
    "    )\n",
    "    \n",
    "    # Train model and measure time\n",
    "    print(f\"Training started...\")\n",
    "    start_time = time.time()\n",
    "    model = rf.fit(train_data)\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\" Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Make predictions and measure time\n",
    "    print(f\"Making predictions...\")\n",
    "    start_time = time.time()\n",
    "    predictions = model.transform(test_data)\n",
    "    predictions.cache()\n",
    "    pred_count = predictions.count()  # Trigger computation\n",
    "    prediction_time = time.time() - start_time\n",
    "    print(f\" Predictions completed in {prediction_time:.2f} seconds\")\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol='label',\n",
    "        predictionCol='prediction',\n",
    "        metricName='accuracy'\n",
    "    )\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(f\" Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Collect metrics\n",
    "    metrics = {\n",
    "        'experiment_id': exp_id,\n",
    "        'num_executors': 1,\n",
    "        'num_trees': num_trees,\n",
    "        'max_depth': max_depth,\n",
    "        'training_time': training_time,\n",
    "        'prediction_time': prediction_time,\n",
    "        'total_time': training_time + prediction_time,\n",
    "        'accuracy': accuracy,\n",
    "        'train_samples': train_count,\n",
    "        'test_samples': test_count\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'model': model,\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0ccdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Experiment 1: 50 trees\n",
    "result_50 = train_and_evaluate_rf(\n",
    "    train_data, test_data, \n",
    "    num_trees=50, \n",
    "    exp_id=\"B1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e33b6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Experiment 2: 100 trees (standard configuration)\n",
    "result_100 = train_and_evaluate_rf(\n",
    "    train_data, test_data, \n",
    "    num_trees=100, \n",
    "    exp_id=\"B2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e6d52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Experiment 3: 200 trees\n",
    "result_200 = train_and_evaluate_rf(\n",
    "    train_data, test_data, \n",
    "    num_trees=200, \n",
    "    exp_id=\"B3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f3489",
   "metadata": {},
   "source": [
    "## 4. Results Summary and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a0c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all baseline results\n",
    "baseline_results = pd.DataFrame([\n",
    "    result_50['metrics'],\n",
    "    result_100['metrics'],\n",
    "    result_200['metrics']\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(baseline_results.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b339dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize baseline performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Training time vs number of trees\n",
    "axes[0].bar(baseline_results['num_trees'], baseline_results['training_time'], \n",
    "            color='steelblue', alpha=0.7)\n",
    "axes[0].set_xlabel('Number of Trees', fontsize=12)\n",
    "axes[0].set_ylabel('Training Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Sequential Baseline: Training Time', fontsize=14)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (trees, time_val) in enumerate(zip(baseline_results['num_trees'], \n",
    "                                           baseline_results['training_time'])):\n",
    "    axes[0].text(trees, time_val, f'{time_val:.1f}s', \n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Plot 2: Accuracy vs number of trees\n",
    "axes[1].plot(baseline_results['num_trees'], baseline_results['accuracy']*100, \n",
    "            marker='o', linewidth=2, markersize=8, color='green')\n",
    "axes[1].set_xlabel('Number of Trees', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Sequential Baseline: Accuracy', fontsize=14)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim([baseline_results['accuracy'].min()*100-5, \n",
    "                   baseline_results['accuracy'].max()*100+5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Baseline performance visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24fb0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export baseline results for comparison with parallel implementation\n",
    "import os\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "os.makedirs('results/metrics', exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "baseline_results.to_csv('results/metrics/baseline_results.csv', index=False)\n",
    "print(\" Baseline results exported to: results/metrics/baseline_results.csv\")\n",
    "\n",
    "# Also save predictions from 100-tree model for correctness validation\n",
    "predictions_100 = result_100['predictions'].select('label', 'prediction').toPandas()\n",
    "predictions_100.to_csv('results/metrics/baseline_predictions_100trees.csv', index=False)\n",
    "print(\" Baseline predictions (100 trees) saved for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b2efa",
   "metadata": {},
   "source": [
    "## 5. Key Findings and Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d64570bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY FINDINGS FROM SEQUENTIAL BASELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Training time scaling\n",
    "time_50 = result_50['metrics']['training_time']\n",
    "time_100 = result_100['metrics']['training_time']\n",
    "time_200 = result_200['metrics']['training_time']\n",
    "\n",
    "print(f\"\\n1. Training Time Scaling:\")\n",
    "print(f\"   - 50 trees:  {time_50:.2f} seconds\")\n",
    "print(f\"   - 100 trees: {time_100:.2f} seconds ({time_100/time_50:.2f}x vs 50 trees)\")\n",
    "print(f\"   - 200 trees: {time_200:.2f} seconds ({time_200/time_100:.2f}x vs 100 trees)\")\n",
    "print(f\"\\n   ➜ Training time scales approximately linearly with number of trees\")\n",
    "\n",
    "# Accuracy analysis\n",
    "acc_50 = result_50['metrics']['accuracy']\n",
    "acc_100 = result_100['metrics']['accuracy']\n",
    "acc_200 = result_200['metrics']['accuracy']\n",
    "\n",
    "print(f\"\\n2. Accuracy Analysis:\")\n",
    "print(f\"   - 50 trees:  {acc_50:.4f} ({acc_50*100:.2f}%)\")\n",
    "print(f\"   - 100 trees: {acc_100:.4f} ({acc_100*100:.2f}%)\")\n",
    "print(f\"   - 200 trees: {acc_200:.4f} ({acc_200*100:.2f}%)\")\n",
    "acc_improvement = (acc_200 - acc_50) * 100\n",
    "print(f\"\\n   ➜ Accuracy improvement from 50 to 200 trees: {acc_improvement:.2f}%\")\n",
    "\n",
    "# Baseline for speedup calculations\n",
    "print(f\"\\n3. Baseline for Parallel Comparison:\")\n",
    "print(f\"   - Using 100 trees as standard configuration\")\n",
    "print(f\"   - Sequential training time: {time_100:.2f} seconds\")\n",
    "print(f\"   - Target speedup with 4 executors: >3.0x\")\n",
    "print(f\"   - Expected parallel time (4 executors): <{time_100/3:.2f} seconds\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446b564",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee444317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpersist cached data\n",
    "train_data.unpersist()\n",
    "test_data.unpersist()\n",
    "result_50['predictions'].unpersist()\n",
    "result_100['predictions'].unpersist()\n",
    "result_200['predictions'].unpersist()\n",
    "\n",
    "print(\" Cache cleared\")\n",
    "\n",
    "# Note: Don't stop Spark session if running more notebooks in same session\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f817349",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook established the sequential baseline for Random Forest training on the Covertype dataset. Key results:\n",
    "\n",
    "- ✅ Successfully loaded and preprocessed 581,012 samples with 54 features\n",
    "- ✅ Trained Random Forest models with 50, 100, and 200 trees\n",
    "- ✅ Measured training times and accuracies for all configurations\n",
    "- ✅ Exported baseline metrics for parallel comparison\n",
    "- ✅ Saved predictions for correctness validation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab1 Kernel",
   "language": "python",
   "name": "lab1_kernel"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
